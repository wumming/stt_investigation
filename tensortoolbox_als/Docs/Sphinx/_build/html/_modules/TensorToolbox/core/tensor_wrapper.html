
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>TensorToolbox.core.tensor_wrapper &#8212; TensorToolbox 0.3.3 documentation</title>
    <link rel="stylesheet" href="../../../_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '0.3.3',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
  </head>
  <body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">TensorToolbox 0.3.3 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for TensorToolbox.core.tensor_wrapper</h1><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># This file is part of TensorToolbox.</span>
<span class="c1">#</span>
<span class="c1"># TensorToolbox is free software: you can redistribute it and/or modify</span>
<span class="c1"># it under the terms of the LGNU Lesser General Public License as published by</span>
<span class="c1"># the Free Software Foundation, either version 3 of the License, or</span>
<span class="c1"># (at your option) any later version.</span>
<span class="c1">#</span>
<span class="c1"># TensorToolbox is distributed in the hope that it will be useful,</span>
<span class="c1"># but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="c1"># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="c1"># LGNU Lesser General Public License for more details.</span>
<span class="c1">#</span>
<span class="c1"># You should have received a copy of the LGNU Lesser General Public License</span>
<span class="c1"># along with TensorToolbox.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="c1">#</span>
<span class="c1"># DTU UQ Library</span>
<span class="c1"># Copyright (C) 2014-2016 The Technical University of Denmark</span>
<span class="c1"># Scientific Computing Section</span>
<span class="c1"># Department of Applied Mathematics and Computer Science</span>
<span class="c1">#</span>
<span class="c1"># Author: Daniele Bigoni</span>
<span class="c1">#</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;TensorWrapper&#39;</span><span class="p">]</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">operator</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">itertools.imap</span> <span class="k">as</span> <span class="nn">map</span>
    <span class="kn">import</span> <span class="nn">itertools.ifilter</span> <span class="k">as</span> <span class="nn">filter</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">os.path</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">numpy.linalg</span> <span class="k">as</span> <span class="nn">npla</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">scipy.linalg</span> <span class="k">as</span> <span class="nn">scla</span>
<span class="kn">import</span> <span class="nn">marshal</span><span class="o">,</span> <span class="nn">types</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">h5py</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">mpi_map</span>
    <span class="n">MPI_SUPPORT</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">MPI_SUPPORT</span> <span class="o">=</span> <span class="kc">False</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="k">import</span> <span class="n">reduce</span>

<span class="kn">from</span> <span class="nn">TensorToolbox.core</span> <span class="k">import</span> <span class="n">idxunfold</span><span class="p">,</span> <span class="n">idxfold</span><span class="p">,</span> <span class="n">expand_idxs</span><span class="p">,</span> <span class="n">storable_object</span>

<div class="viewcode-block" id="TensorWrapper"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper">[docs]</a><span class="k">class</span> <span class="nc">TensorWrapper</span><span class="p">(</span><span class="n">storable_object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; A tensor wrapper is a data structure W that given a multi-dimensional scalar function f(X,params), and a set of coordinates {{x1}_i1,{x2}_i2,..,{xd}_id} indexed by the multi index {i1,..,id}, let you access f(x1_i1,..,xd_id) by W[i1,..,id]. The function evaluations are performed &quot;as needed&quot; and stored for future accesses.</span>

<span class="sd">    :param f: multi-dimensional scalar function of type f(x,params), x being a list.</span>
<span class="sd">    :param list X: list of arrays with coordinates for each dimension</span>
<span class="sd">    :param tuple params: parameters to be passed to function f</span>
<span class="sd">    :param list W: list of arrays with weights for each dimension</span>
<span class="sd">    :param string twtype: &#39;array&#39; values are stored whenever computed, &#39;view&#39; values are never stored and function f is always called</span>
<span class="sd">    :param strung ftype: &#39;serial&#39; if it can only evaluate the function pointwise,</span>
<span class="sd">       &#39;vector&#39; if it can evaluate many points at once.</span>
<span class="sd">    :param dict data: initialization data of the Tensor Wrapper (already computed entries)</span>
<span class="sd">    :param type dtype: type of output to be expected from f</span>
<span class="sd">    :param str store_file: file where to store the data</span>
<span class="sd">    :param object store_object: a storable object that must be stored in place of the TensorWrapper</span>
<span class="sd">    :param bool store_freq: how frequently to store the TensorWrapper (seconds)</span>
<span class="sd">    :param bool store_overwrite: whether to overwrite pre-existing files.</span>
<span class="sd">    :param bool empty: Creates an instance without initializing it. All the content can be initialized using the ``setstate()`` function.</span>
<span class="sd">    :param int maxprocs: Number of processors to be used in the function evaluation (MPI)</span>
<span class="sd">    :param bool marshal_f: whether to marshal the function or not</span>

<span class="sd">    Several shape parameters are used by the TensorWrapper in order to keep track of reshaping and slicings, without affecting the underlying shape of the tensor which is always preserved. The following table lists the existing shapes and their meaning.</span>

<span class="sd">    +------------------------------------------------+--------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">    | Shape attribute/function                       | Applied transformations (ordered)    | Description                                                                                                                                                                                                                                                      |</span>
<span class="sd">    +================================================+======================================+==================================================================================================================================================================================================================================================================+</span>
<span class="sd">    | :py:meth:`~TensorWrapper.get_global_shape`     | None                                 | The original shape of the tensor. This shape can be modified only  through a refinement of the grid using the function :py:meth:`~TensorWrapper.refine`.                                                                                                         |</span>
<span class="sd">    +------------------------------------------------+--------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">    | :py:meth:`~TensorWrapper.get_view_shape`       | VIEW                                 | The particular view of the tensor, defined by the view in :py:attr:`TensorWrapper.maps` set active using :py:meth:`~TensorWrapper.set_active_view`.                                                                                                              |</span>
<span class="sd">    +------------------------------------------------+--------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">    | :py:meth:`~TensorWrapper.get_extended_shape`   | VIEW, QUANTICS                       | The shape of the extended tensor in order to allow for the quantics folding with basis :py:attr:`TensorWrapper.Q`.                                                                                                                                               |</span>
<span class="sd">    +------------------------------------------------+--------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">    | :py:meth:`~TensorWrapper.get_ghost_shape`      | VIEW, QUANTICS, RESHAPE              | The shape of the tensor reshaped using :py:meth:`~TensorWrapper.reshape`. If a Quantics folding is pre-applied, then the reshape is on the extended shape.                                                                                                       |</span>
<span class="sd">    +------------------------------------------------+--------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">    | :py:meth:`~TensorWrapper.get_shape`            | VIEW, QUANTICS, RESHAPE, FIX_IDXS    | The shape of the tensor with :py:meth:`~TensorWrapper.fix_indices` and :py:meth:`~TensorWrapper.release_indices`. This is the view that is always used when the tensor is accessed through the function :py:meth:`~TensorWrapper.__getitem__` (i.e. ``TW[...]``) |</span>
<span class="sd">    +------------------------------------------------+--------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>

<span class="sd">    .. document private functions</span>
<span class="sd">    .. automethod:: __getitem__</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">propagate</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">ch</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">StreamHandler</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">)</span>
    <span class="n">formatter</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">Formatter</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%(asctime)s</span><span class="s2"> </span><span class="si">%(levelname)s</span><span class="s2">:</span><span class="si">%(name)s</span><span class="s2">: </span><span class="si">%(message)s</span><span class="s2">&quot;</span><span class="p">,</span>
                                  <span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2"> %H:%M:%S&quot;</span><span class="p">)</span>
    <span class="n">ch</span><span class="o">.</span><span class="n">setFormatter</span><span class="p">(</span><span class="n">formatter</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">addHandler</span><span class="p">(</span><span class="n">ch</span><span class="p">)</span>

    <span class="c1"># FILL_VALUE = 0.0            # Value used to fill powQ tensors</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">twtype</span><span class="o">=</span><span class="s1">&#39;array&#39;</span><span class="p">,</span> <span class="n">ftype</span><span class="o">=</span><span class="s1">&#39;serial&#39;</span><span class="p">,</span>
                 <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">,</span>
                 <span class="n">store_file</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">store_object</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">store_freq</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">store_overwrite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">empty</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">maxprocs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">marshal_f</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">TensorWrapper</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">store_file</span><span class="p">,</span> 
                                           <span class="n">store_freq</span><span class="o">=</span><span class="n">store_freq</span><span class="p">,</span> 
                                           <span class="n">store_overwrite</span><span class="o">=</span><span class="n">store_overwrite</span><span class="p">)</span>

        <span class="c1">#######################################</span>
        <span class="c1"># List of attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_code</span> <span class="o">=</span> <span class="kc">None</span>               <span class="c1"># Marshal string of the function f</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">twtype</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ftype</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">maps</span> <span class="o">=</span> <span class="p">{}</span>          <span class="c1"># Multiple views</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">view</span> <span class="o">=</span> <span class="kc">None</span>        <span class="c1"># Multiple views</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">serialize_list</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;W&#39;</span><span class="p">,</span> <span class="s1">&#39;dtype&#39;</span><span class="p">,</span> <span class="s1">&#39;params&#39;</span><span class="p">,</span> <span class="s1">&#39;twtype&#39;</span><span class="p">,</span> <span class="s1">&#39;ftype&#39;</span><span class="p">,</span>
                                     <span class="s1">&#39;f_code&#39;</span><span class="p">,</span> <span class="s1">&#39;maps&#39;</span><span class="p">,</span> <span class="s1">&#39;view&#39;</span><span class="p">]</span> <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">subserialize_list</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span> <span class="p">[]</span> <span class="p">)</span>

        <span class="c1"># Attributes which are not serialized and need to be reset on reload</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">store_object</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__maxprocs</span> <span class="o">=</span> <span class="kc">None</span>             <span class="c1"># Number of processors to be used (MPI)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="kc">None</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">stored_keys</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># Set of stored keys (to improve the saving speed)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">active_weights</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># End list of attributes</span>
        <span class="c1">#################################</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">active_weights</span> <span class="o">=</span> <span class="kc">False</span>        
        <span class="bp">self</span><span class="o">.</span><span class="n">stored_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">empty</span><span class="p">:</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">set_f</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="n">marshal_f</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ftype</span> <span class="o">=</span> <span class="n">ftype</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="s1">&#39;full&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span> <span class="s1">&#39;X_map&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> 
                                  <span class="s1">&#39;idx_map&#39;</span><span class="p">:</span> <span class="p">[</span> <span class="nb">range</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="p">],</span>
                                  <span class="s1">&#39;Q&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                                  <span class="s1">&#39;ghost_shape&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                                  <span class="s1">&#39;fix_idxs&#39;</span><span class="p">:</span> <span class="p">[],</span>
                                  <span class="s1">&#39;fix_dims&#39;</span><span class="p">:</span> <span class="p">[]</span> <span class="p">}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_active_view</span><span class="p">(</span><span class="s1">&#39;full&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ndim</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_size</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">twtype</span> <span class="o">=</span> <span class="n">twtype</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">set_store_object</span><span class="p">(</span><span class="n">store_object</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">set_maxprocs</span><span class="p">(</span><span class="n">maxprocs</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">twtype</span> <span class="o">==</span> <span class="s1">&#39;array&#39;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">data</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">{}</span> <span class="c1"># Dictionary in python behave as a hash-table</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">twtype</span> <span class="o">!=</span> <span class="s1">&#39;view&#39;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Tensor Wrapper type not existent. Use &#39;array&#39; or &#39;view&#39;&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">TensorWrapper</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__getstate__</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">state</span><span class="p">,</span><span class="n">f</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">store_object</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TensorWrapper</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__setstate__</span><span class="p">(</span> <span class="n">state</span><span class="p">,</span> <span class="n">store_object</span> <span class="p">)</span>
        <span class="c1"># Reset parameters</span>
        <span class="k">if</span> <span class="n">f</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset_f_marshal</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">set_f</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_store_object</span><span class="p">(</span> <span class="n">store_object</span> <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fix_idxs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fix_dims</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__maxprocs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_ghost_shape</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">active_weights</span> <span class="o">=</span> <span class="kc">False</span>

<div class="viewcode-block" id="TensorWrapper.set_weights"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.set_weights">[docs]</a>    <span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">W</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Set a new list of weights for the tensor</span>
<span class="sd">        :param list W: list of np.ndarray with weights for each dimension</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_global_shape</span><span class="p">()):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The provided set of weights has not the right dimension: len(W)=</span><span class="si">%d</span><span class="s2">, dim=</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_global_shape</span><span class="p">())))</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span> <span class="p">[</span> <span class="nb">len</span><span class="p">(</span><span class="n">wi</span><span class="p">)</span> <span class="o">!=</span> <span class="n">si</span> <span class="k">for</span> <span class="n">wi</span><span class="p">,</span><span class="n">si</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">get_global_shape</span><span class="p">())</span> <span class="p">]</span> <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The provided set of weights contains at least one dimension which is not conformal with the tensor grid.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W</span></div>

<div class="viewcode-block" id="TensorWrapper.set_active_weights"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.set_active_weights">[docs]</a>    <span class="k">def</span> <span class="nf">set_active_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">flag</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Set whether to use the weights or not.</span>

<span class="sd">        :param bool flag: If ``True`` the items returned by the Tensor Wrapper will be weighted according to the weights provided at construction time. If ``False`` the original values of the function will be returned.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">active_weights</span> <span class="o">=</span> <span class="n">flag</span></div>

    <span class="k">def</span> <span class="nf">getstate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__getstate__</span><span class="p">();</span>
    
    <span class="k">def</span> <span class="nf">setstate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">state</span><span class="p">,</span><span class="n">f</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">store_object</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__setstate__</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">store_object</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">h5store</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h5file</span><span class="p">):</span>
        <span class="c1"># Store the data table in the h5 file. Update if possible.</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">tw_grp</span> <span class="o">=</span> <span class="n">h5file</span><span class="p">[</span><span class="s1">&#39;TW&#39;</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="c1"># Create the group, the data structure and dump data</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">tw_grp</span> <span class="o">=</span> <span class="n">h5file</span><span class="o">.</span><span class="n">create_group</span><span class="p">(</span><span class="s1">&#39;TW&#39;</span><span class="p">)</span>
                <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
                <span class="n">values</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
                <span class="n">tw_grp</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="s2">&quot;keys&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">keys</span><span class="p">,</span> <span class="n">maxshape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">get_ndim</span><span class="p">())</span> <span class="p">)</span>
                <span class="n">tw_grp</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">values</span><span class="p">,</span>
                                      <span class="n">maxshape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,)</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">shape</span> <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">stored_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span> <span class="n">keys</span> <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Increase the shape of the datasets to accommodate for the new data</span>
            <span class="n">tw_grp</span><span class="p">[</span><span class="s2">&quot;keys&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">),</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">tw_grp</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">),</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># Store by data chunk</span>
            <span class="n">N</span> <span class="o">=</span> <span class="mi">100000</span>
            <span class="n">it</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">dvals</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tw_grp</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stored_keys</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">):</span>
                <span class="c1"># Get the missing data</span>
                <span class="n">new_data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stored_keys</span><span class="p">,</span> 
                                       <span class="n">itertools</span><span class="o">.</span><span class="n">islice</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> 
                                                         <span class="n">it</span><span class="o">*</span><span class="n">N</span><span class="p">,</span> 
                                                         <span class="nb">min</span><span class="p">((</span><span class="n">it</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">))</span> 
                                                     <span class="p">)</span> 
                                   <span class="p">))</span>
                <span class="n">it</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="c1"># Assign new values to the datasets</span>
                <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">new_data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
                <span class="n">values</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">new_data</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
                <span class="n">tw_grp</span><span class="p">[</span><span class="s2">&quot;keys&quot;</span><span class="p">][</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stored_keys</span><span class="p">):</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stored_keys</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">new_data</span><span class="p">),:]</span> <span class="o">=</span> <span class="n">keys</span>
                <span class="n">tw_grp</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">][</span> <span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stored_keys</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stored_keys</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">new_data</span><span class="p">),</span><span class="kc">None</span><span class="p">),)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">([</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">)]</span><span class="o">*</span><span class="p">(</span><span class="n">dvals</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="p">]</span> <span class="o">=</span> <span class="n">values</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">stored_keys</span> <span class="o">|=</span> <span class="nb">set</span><span class="p">(</span> <span class="n">keys</span> <span class="p">)</span>

    <span class="k">def</span> <span class="nf">h5load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h5file</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">tw_grp</span> <span class="o">=</span> <span class="n">h5file</span><span class="p">[</span><span class="s1">&#39;TW&#39;</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="c1"># The data structure is empty. Do nothing.</span>
            <span class="k">pass</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Load by data chunk</span>
            <span class="n">N</span> <span class="o">=</span> <span class="mi">100000</span>
            <span class="n">it</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">dvals</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tw_grp</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">Ndata</span> <span class="o">=</span> <span class="n">tw_grp</span><span class="p">[</span><span class="s2">&quot;keys&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">Ndata</span><span class="p">:</span>
                <span class="n">keys</span> <span class="o">=</span> <span class="n">tw_grp</span><span class="p">[</span><span class="s2">&quot;keys&quot;</span><span class="p">][</span><span class="n">it</span><span class="o">*</span><span class="n">N</span><span class="p">:</span><span class="nb">min</span><span class="p">((</span><span class="n">it</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">,</span><span class="n">Ndata</span><span class="p">),</span> <span class="p">:]</span>
                <span class="n">values</span> <span class="o">=</span> <span class="n">tw_grp</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">][</span> <span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="n">it</span><span class="o">*</span><span class="n">N</span><span class="p">,</span> <span class="nb">min</span><span class="p">((</span><span class="n">it</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">,</span><span class="n">Ndata</span><span class="p">),</span><span class="kc">None</span><span class="p">),)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">([</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">)]</span><span class="o">*</span><span class="p">(</span><span class="n">dvals</span><span class="o">-</span><span class="mi">1</span><span class="p">))]</span>
                <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">dvals</span><span class="o">=</span><span class="n">dvals</span><span class="p">):</span>
                    <span class="k">return</span> <span class="p">(</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">keys</span><span class="p">[</span><span class="n">i</span><span class="p">,:]),</span> <span class="n">values</span><span class="p">[(</span><span class="n">i</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">([</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">)]</span><span class="o">*</span><span class="p">(</span><span class="n">dvals</span><span class="o">-</span><span class="mi">1</span><span class="p">))]</span> <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">update</span><span class="p">(</span> <span class="nb">map</span><span class="p">(</span> <span class="n">f</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="n">keys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="p">)</span> <span class="p">)</span>
                <span class="n">it</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stored_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="p">)</span>
    
<div class="viewcode-block" id="TensorWrapper.to_v_0_3_0"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.to_v_0_3_0">[docs]</a>    <span class="k">def</span> <span class="nf">to_v_0_3_0</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">store_location</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Upgrade to v0.3.0</span>
<span class="sd">        </span>
<span class="sd">        :param string filename: path to the filename. This must be the main filename with no extension.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TensorWrapper</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">to_v_0_3_0</span><span class="p">(</span><span class="n">store_location</span><span class="p">)</span>
        <span class="c1"># Upgrade serialize list</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">serialize_list</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span> <span class="s1">&#39;data&#39;</span> <span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">TensorWrapper</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">twtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">twtype</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>

    <span class="c1">#####################################################</span>
    <span class="c1">#               SHAPES AND VIEWS                    #</span>
    <span class="c1">#####################################################</span>

    <span class="c1">##########</span>
    <span class="c1"># GLOBAL #</span>
    <span class="c1">##########</span>
<div class="viewcode-block" id="TensorWrapper.get_global_shape"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.get_global_shape">[docs]</a>    <span class="k">def</span> <span class="nf">get_global_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Always returns the shape of the underlying tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="p">[</span> <span class="nb">len</span><span class="p">(</span><span class="n">coord</span><span class="p">)</span> <span class="k">for</span> <span class="n">coord</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="p">]</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="TensorWrapper.get_global_ndim"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.get_global_ndim">[docs]</a>    <span class="k">def</span> <span class="nf">get_global_ndim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Always returns the ndim of the underlying tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_global_shape</span><span class="p">())</span></div>
    
<div class="viewcode-block" id="TensorWrapper.get_global_size"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.get_global_size">[docs]</a>    <span class="k">def</span> <span class="nf">get_global_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Always returns the size of the underlying tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">reduce</span><span class="p">(</span><span class="n">operator</span><span class="o">.</span><span class="n">mul</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_global_shape</span><span class="p">(),</span> <span class="mi">1</span><span class="p">)</span></div>
    
    <span class="c1">#########</span>
    <span class="c1"># VIEWS #</span>
    <span class="c1">#########</span>
<div class="viewcode-block" id="TensorWrapper.get_view_shape"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.get_view_shape">[docs]</a>    <span class="k">def</span> <span class="nf">get_view_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Always returns the shape of the current view</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="p">[</span> <span class="nb">len</span><span class="p">(</span><span class="n">coord</span><span class="p">)</span> <span class="k">for</span> <span class="n">coord</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;X_map&#39;</span><span class="p">]</span> <span class="p">]</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span></div>

<div class="viewcode-block" id="TensorWrapper.get_view_ndim"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.get_view_ndim">[docs]</a>    <span class="k">def</span> <span class="nf">get_view_ndim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Always returns the ndim of the current view</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;X_map&#39;</span><span class="p">])</span></div>
    
<div class="viewcode-block" id="TensorWrapper.get_view_size"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.get_view_size">[docs]</a>    <span class="k">def</span> <span class="nf">get_view_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Always returns the size of the current view</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">reduce</span><span class="p">(</span><span class="n">operator</span><span class="o">.</span><span class="n">mul</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_view_shape</span><span class="p">(),</span> <span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="TensorWrapper.set_active_view"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.set_active_view">[docs]</a>    <span class="k">def</span> <span class="nf">set_active_view</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">view</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Set a view among the ones in ``self.maps``.</span>
<span class="sd">        </span>
<span class="sd">        :param str view: name of the view to be set as active</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">view</span> <span class="o">=</span> <span class="n">view</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_shape</span><span class="p">()</span></div>
        
<div class="viewcode-block" id="TensorWrapper.set_view"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.set_view">[docs]</a>    <span class="k">def</span> <span class="nf">set_view</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">view</span><span class="p">,</span> <span class="n">X_map</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Set or add a view to ``self.maps``. This resest all the existing reshape parameters in existing views.</span>
<span class="sd">        </span>
<span class="sd">        :param str view: name of the view to be added</span>
<span class="sd">        :param list X_map: list of coordinates of the new view</span>
<span class="sd">        :param float tol: tolerance for the matching of coordinates</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">tol</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span> <span class="n">tol</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">spacing</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">idx_map</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">d</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X_map</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span> <span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;TensorWrapperView: the input coordinates must be sorted&quot;</span><span class="p">)</span>
            
            <span class="n">idx_map</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
            <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
                <span class="k">while</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">d</span><span class="p">]):</span>
                    <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span> <span class="n">val</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">d</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="p">)</span> <span class="o">&lt;=</span> <span class="n">tol</span> <span class="p">:</span>
                        <span class="n">idx_map</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">j</span> <span class="p">)</span>
                        <span class="k">break</span>
                    <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">d</span><span class="p">]):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;TensorWrapperView: the input coordinates are not a subset of the full coordinates&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="n">view</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span> <span class="s1">&#39;X_map&#39;</span><span class="p">:</span> <span class="n">X_map</span><span class="p">,</span> 
                            <span class="s1">&#39;idx_map&#39;</span><span class="p">:</span> <span class="n">idx_map</span><span class="p">,</span>
                            <span class="s1">&#39;Q&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                            <span class="s1">&#39;ghost_shape&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                            <span class="s1">&#39;fix_idxs&#39;</span><span class="p">:</span> <span class="p">[],</span>
                            <span class="s1">&#39;fix_dims&#39;</span><span class="p">:</span> <span class="p">[]}</span></div>

<div class="viewcode-block" id="TensorWrapper.refine"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.refine">[docs]</a>    <span class="k">def</span> <span class="nf">refine</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_new</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Refine the global discretization. The new discretization must contain the old one.</span>

<span class="sd">        This function takes care of updating all the indices in the global view as well in all the other views.</span>
<span class="sd">        </span>
<span class="sd">        :param list X_new: list of coordinates of the new refinement</span>
<span class="sd">        :param float tol: tolerance for the matching of coordinates</span>

<span class="sd">        .. warning:: Any existing reshaping of the views is discarded.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">tol</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span> <span class="n">tol</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">spacing</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">top_map</span> <span class="o">=</span> <span class="p">[]</span>            <span class="c1"># Map from the old full coord to X_new</span>
        <span class="k">for</span> <span class="n">d</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X_new</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span> <span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;TensorWrapperView: the input coordinates must be sorted&quot;</span><span class="p">)</span>
            
            <span class="n">top_map</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
            <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">d</span><span class="p">]:</span>
                <span class="k">while</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span> <span class="n">val</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="p">)</span> <span class="o">&lt;=</span> <span class="n">tol</span><span class="p">:</span>
                        <span class="n">top_map</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">j</span> <span class="p">)</span>
                        <span class="k">break</span>
                    <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;TensorWrapperView: the full coordinates are not a subset of the new coordinates&quot;</span><span class="p">)</span>
            
        <span class="c1"># Update all keys in data</span>
        <span class="n">new_data</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="p">(</span><span class="n">old_key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">popitem</span><span class="p">()</span>
            <span class="n">new_key</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span> <span class="p">[</span> <span class="n">top_map</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">old_key</span><span class="p">)</span> <span class="p">]</span> <span class="p">)</span>
            <span class="n">new_data</span><span class="p">[</span><span class="n">new_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">new_data</span>
        
        <span class="c1"># Update the coordinates</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X_new</span>

        <span class="c1"># Update all the views</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="s1">&#39;full&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span> <span class="s1">&#39;X_map&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> 
                              <span class="s1">&#39;idx_map&#39;</span><span class="p">:</span> <span class="p">[</span> <span class="nb">range</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="p">],</span>
                              <span class="s1">&#39;Q&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                              <span class="s1">&#39;ghost_shape&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                              <span class="s1">&#39;fix_idxs&#39;</span><span class="p">:</span> <span class="p">[],</span>
                              <span class="s1">&#39;fix_dims&#39;</span><span class="p">:</span> <span class="p">[]</span> <span class="p">}</span>
        <span class="k">for</span> <span class="n">view</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">view</span> <span class="o">!=</span> <span class="s1">&#39;full&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">set_view</span><span class="p">(</span> <span class="n">view</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;X_map&#39;</span><span class="p">]</span> <span class="p">)</span></div>

    <span class="c1">#########################</span>
    <span class="c1"># EXTENDED for Quantics #</span>
    <span class="c1">#########################</span>
<div class="viewcode-block" id="TensorWrapper.get_extended_shape"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.get_extended_shape">[docs]</a>    <span class="k">def</span> <span class="nf">get_extended_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; If the quantics folding has been performed on the current view, then this returns the shape of the extended tensor to the next power of Q. If the folding has not been performed, this returns the view shape.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;Q&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_view_shape</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;Q&#39;</span><span class="p">]</span><span class="o">**</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">s</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;Q&#39;</span><span class="p">]))</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_view_shape</span><span class="p">()</span> <span class="p">]</span> <span class="p">)</span></div>

<div class="viewcode-block" id="TensorWrapper.get_extended_ndim"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.get_extended_ndim">[docs]</a>    <span class="k">def</span> <span class="nf">get_extended_ndim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; If the quantics folding has been performed on the current view, then this returns the number of dimensions of the extended tensor to the next power of Q. If the folding has not been performed, this returns an error.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_extended_shape</span><span class="p">())</span></div>
    
<div class="viewcode-block" id="TensorWrapper.get_extended_size"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.get_extended_size">[docs]</a>    <span class="k">def</span> <span class="nf">get_extended_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; If the quantics folding has been performed on the current view, then this returns the size of the extended tensor to the next power of Q. If the folding has not been performed, this returns an error.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">reduce</span><span class="p">(</span><span class="n">operator</span><span class="o">.</span><span class="n">mul</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_extended_shape</span><span class="p">())</span></div>
    
<div class="viewcode-block" id="TensorWrapper.set_Q"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.set_Q">[docs]</a>    <span class="k">def</span> <span class="nf">set_Q</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Q</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Set the quantics folding base for the current view.</span>

<span class="sd">        This will unset any fixed index for the current view set using :py:meth:`~TensorWrapper.fix_indices`.</span>
<span class="sd">        </span>
<span class="sd">        :param int Q: folding base.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;Q&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Q</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;ghost_shape&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span> <span class="n">Q</span><span class="o">**</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">s</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">Q</span><span class="p">))</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_view_shape</span><span class="p">()</span> <span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;fix_idxs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;fix_dims&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_shape</span><span class="p">()</span></div>

<div class="viewcode-block" id="TensorWrapper.reset_shape"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.reset_shape">[docs]</a>    <span class="k">def</span> <span class="nf">reset_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Reset the shape of the tensor erasing the reshape and quantics foldings.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;Q&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;ghost_shape&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_shape</span><span class="p">()</span></div>

    <span class="c1">#########</span>
    <span class="c1"># GHOST #</span>
    <span class="c1">#########</span>
<div class="viewcode-block" id="TensorWrapper.get_ghost_shape"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.get_ghost_shape">[docs]</a>    <span class="k">def</span> <span class="nf">get_ghost_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; If the ``ghost_shape`` is set for this view, then it returns the shape obtained after quantics folding by the function :py:meth:`~TensorWrapper.set_Q` or after reshaping by the function :py:meth:`~TensorWrapper.reshape`. Otherwise the shape of the extended shape is returned.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;ghost_shape&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;ghost_shape&#39;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_extended_shape</span><span class="p">()</span></div>
    
<div class="viewcode-block" id="TensorWrapper.get_ghost_ndim"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.get_ghost_ndim">[docs]</a>    <span class="k">def</span> <span class="nf">get_ghost_ndim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; If the ``ghost_shape`` is set for this view, then it returns the number of dimensions obtained after quantics folding by the function :py:meth:`~TensorWrapper.set_Q` or after reshaping by the function :py:meth:`~TensorWrapper.reshape`. Otherwise the number of dimensions of the view is returned.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_ghost_shape</span><span class="p">())</span></div>

<div class="viewcode-block" id="TensorWrapper.get_ghost_size"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.get_ghost_size">[docs]</a>    <span class="k">def</span> <span class="nf">get_ghost_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; If the ``ghost_shape`` is set for this view, then it returns the size obtained after quantics folding by the function :py:meth:`~TensorWrapper.set_Q` or after reshaping by the function :py:meth:`~TensorWrapper.reshape`. Otherwise the size of the view is returned.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">reduce</span><span class="p">(</span><span class="n">operator</span><span class="o">.</span><span class="n">mul</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ghost_shape</span><span class="p">())</span></div>

<div class="viewcode-block" id="TensorWrapper.reset_ghost_shape"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.reset_ghost_shape">[docs]</a>    <span class="k">def</span> <span class="nf">reset_ghost_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Reset the shape of the tensor erasing the reshape and quantics foldings.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;ghost_shape&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_shape</span><span class="p">()</span></div>
    
<div class="viewcode-block" id="TensorWrapper.reshape"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.reshape">[docs]</a>    <span class="k">def</span> <span class="nf">reshape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">newshape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Reshape the tensor. The number of items in the new shape must be consistent with :py:meth:`~TensorWrapper.get_extended_size`, i.e. with the number of items in the extended quantics size or the view size if ``Q`` is not set for this view.</span>

<span class="sd">        This will unset any fixed index for the current view set using :py:meth:`~TensorWrapper.fix_indices`.</span>

<span class="sd">        :param list newshape: new shape to be applied to the tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">reduce</span><span class="p">(</span><span class="n">operator</span><span class="o">.</span><span class="n">mul</span><span class="p">,</span> <span class="n">newshape</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_extended_size</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;ghost_shape&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">newshape</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;fix_idxs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;fix_dims&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_shape</span><span class="p">()</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;TensorWrapper.reshape: total size of new tensor must be unchanged&#39;</span><span class="p">)</span></div>
    
    <span class="c1">###########</span>
    <span class="c1"># FIX_IDX #</span>
    <span class="c1">###########</span>
<div class="viewcode-block" id="TensorWrapper.get_shape"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.get_shape">[docs]</a>    <span class="k">def</span> <span class="nf">get_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Always returns the shape of the actual tensor view</span>
<span class="sd">        </span>
<span class="sd">        .. note: use :py:meth:`TensorWrapper.get_global_shape` to get the shape of the original tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">([</span> <span class="n">s</span> <span class="k">for</span> <span class="n">dim</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_ghost_shape</span><span class="p">())</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">dim</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;fix_dims&#39;</span><span class="p">])</span> <span class="p">])</span></div>
    
<div class="viewcode-block" id="TensorWrapper.get_ndim"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.get_ndim">[docs]</a>    <span class="k">def</span> <span class="nf">get_ndim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Always returns the number of dimensions of the tensor view</span>
<span class="sd">        </span>
<span class="sd">        .. note: use :py:meth:`TensorWrapper.get_global_ndim` to get the number of dimensions of the original tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span></div>

<div class="viewcode-block" id="TensorWrapper.get_size"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.get_size">[docs]</a>    <span class="k">def</span> <span class="nf">get_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Always returns the size of the tensor view</span>
<span class="sd">        </span>
<span class="sd">        .. note: use :py:meth:`TensorWrapper.get_global_size` to get the size of the original tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">reduce</span><span class="p">(</span><span class="n">operator</span><span class="o">.</span><span class="n">mul</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span> <span class="mi">1</span><span class="p">)</span></div>
    
    <span class="k">def</span> <span class="nf">update_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_size</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ndim</span><span class="p">()</span>
    
<div class="viewcode-block" id="TensorWrapper.fix_indices"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.fix_indices">[docs]</a>    <span class="k">def</span> <span class="nf">fix_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idxs</span><span class="p">,</span> <span class="n">dims</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Fix some of the indices in the tensor wrapper and reshape/resize it accordingly. The internal storage of the data is still done with respect to the global indices, but once some indices are fixed, the TensorWrapper can be accessed using just the remaining free indices.</span>
<span class="sd">        </span>
<span class="sd">        :param list idxs: list of indices to be fixed</span>
<span class="sd">        :param list dims: list of dimensions to which the indices refer to</span>
<span class="sd">        </span>
<span class="sd">        .. note: ``len(idxs) == len(dims)``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">idxs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dims</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;TensorToolbox.TensorWrapper.fix_indices: len(idxs) == len(dims) violated&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">dims</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;TensorToolbox.TensorWrapper.fix_indices: the list of dimensions must contain unique entries only.&quot;</span><span class="p">)</span>
        
        <span class="c1"># Reorder the lists</span>
        <span class="n">i_ord</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dims</span><span class="p">)),</span> <span class="n">key</span><span class="o">=</span><span class="n">dims</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;fix_idxs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span> <span class="n">idxs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">i_ord</span> <span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;fix_dims&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span> <span class="n">dims</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">i_ord</span> <span class="p">]</span>
        <span class="c1"># Update shape, ndim and size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_shape</span><span class="p">()</span></div>
    
<div class="viewcode-block" id="TensorWrapper.release_indices"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.release_indices">[docs]</a>    <span class="k">def</span> <span class="nf">release_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Release all the indices in the tensor wrapper which were fixed using :py:meth:`~TensorWrapper.fix_indices`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;fix_idxs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;fix_dims&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_shape</span><span class="p">()</span></div>

    <span class="c1">#####################################################</span>
    <span class="c1">#            INDEX TRANSFORMATIONS                  #</span>
    <span class="c1">#####################################################</span>

    <span class="c1">###################</span>
    <span class="c1"># GLOBAL to SHAPE #</span>
    <span class="c1">###################</span>
<div class="viewcode-block" id="TensorWrapper.global_to_view"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.global_to_view">[docs]</a>    <span class="k">def</span> <span class="nf">global_to_view</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idxs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; This maps the index from the global shape to the view shape.</span>
<span class="sd">        </span>
<span class="sd">        :param tuple idxs: tuple representing an index to be transformed.</span>
<span class="sd">        </span>
<span class="sd">        .. note:: no slicing is admitted here. Preprocess ``idxs`` with :py:meth:`expand_idxs` if slicing is required.</span>
<span class="sd">        .. note:: this returns an error if the ``idxs`` do not belong to the index mapping of the current view.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx_max</span><span class="p">[</span><span class="n">d</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span><span class="p">,</span><span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">idxs</span><span class="p">)</span> <span class="p">]</span> <span class="p">)</span></div>
    
<div class="viewcode-block" id="TensorWrapper.view_to_ghost"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.view_to_ghost">[docs]</a>    <span class="k">def</span> <span class="nf">view_to_ghost</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idxs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; This maps the index from the view to the ghost shape.</span>
<span class="sd">        </span>
<span class="sd">        :param list idxs: list of indices to be transformed</span>

<span class="sd">        .. note:: no slicing is admitted here. Preprocess ``idxs`` with :py:meth:`expand_idxs` if slicing is required.</span>
<span class="sd">        .. note:: this returns an error if the ghost shape is obtained by quantics folding, because the one view index can be pointing to many indices in the folding.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;Q&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="bp">NotImplemented</span><span class="p">(</span><span class="s2">&quot;This operation is undefined because one view idx can point to many q indices&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">idxfold</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ghost_shape</span><span class="p">(),</span> <span class="n">idxunfold</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_view_shape</span><span class="p">(),</span> <span class="n">idxs</span> <span class="p">)</span> <span class="p">)</span></div>
    
<div class="viewcode-block" id="TensorWrapper.global_to_ghost"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.global_to_ghost">[docs]</a>    <span class="k">def</span> <span class="nf">global_to_ghost</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">idxs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; This maps the index from the global shape to the ghost shape.</span>
<span class="sd">        </span>
<span class="sd">        :param list idxs: list of indices to be transformed</span>

<span class="sd">        .. note:: no slicing is admitted here. Preprocess ``idxs`` with :py:meth:`expand_idxs` if slicing is required.</span>

<span class="sd">        For :py:meth:`TensorWrapper` ``A``, this corresponds to:</span>
<span class="sd">        </span>
<span class="sd">        &gt;&gt;&gt; A.view_to_ghost( A.global_to_view( idxs ) )</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">view_to_ghost</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_to_view</span><span class="p">(</span> <span class="n">idxs</span> <span class="p">)</span> <span class="p">)</span></div>

    <span class="c1">###################</span>
    <span class="c1"># SHAPE to GLOBAL #</span>
    <span class="c1">###################</span>
<div class="viewcode-block" id="TensorWrapper.shape_to_ghost"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.shape_to_ghost">[docs]</a>    <span class="k">def</span> <span class="nf">shape_to_ghost</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idxs_in</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; This maps the index from the current shape of the view (fixed indices) to the ghost shape.</span>
<span class="sd">        </span>
<span class="sd">        :param list idxs_in: list of indices to be transformed</span>

<span class="sd">        .. note:: slicing is admitted here.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">idxs</span> <span class="o">=</span> <span class="n">idxs_in</span><span class="p">[:]</span>
        <span class="c1"># Insert the fixed indices</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;fix_dims&#39;</span><span class="p">]:</span>
            <span class="n">idxs</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;fix_idxs&#39;</span><span class="p">][</span> <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;fix_dims&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="p">)</span>
        <span class="k">return</span> <span class="n">idxs</span></div>
    
    <span class="k">def</span> <span class="nf">ghost_to_extended</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idxs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">idxfold</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_extended_shape</span><span class="p">(),</span> <span class="n">idxunfold</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ghost_shape</span><span class="p">(),</span> <span class="n">idxs</span> <span class="p">)</span> <span class="p">)</span>

<div class="viewcode-block" id="TensorWrapper.ghost_to_view"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.ghost_to_view">[docs]</a>    <span class="k">def</span> <span class="nf">ghost_to_view</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idxs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; This maps the index from the current ghost shape of the view to the view shape.</span>
<span class="sd">        </span>
<span class="sd">        :param list idxs_in: list of indices to be transformed</span>

<span class="sd">        .. note:: no slicing is admitted here. Preprocess ``idxs`` with :py:meth:`expand_idxs` if slicing is required.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;Q&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span> <span class="p">[</span> <span class="p">(</span> <span class="n">i</span> <span class="k">if</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">N</span> <span class="k">else</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span> <span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">N</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ghost_to_extended</span><span class="p">(</span><span class="n">idxs</span><span class="p">),</span><span class="bp">self</span><span class="o">.</span><span class="n">get_view_shape</span><span class="p">())</span> <span class="p">]</span> <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">idxs</span> <span class="o">=</span> <span class="n">idxfold</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_view_shape</span><span class="p">(),</span> <span class="n">idxunfold</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ghost_shape</span><span class="p">(),</span> <span class="n">idxs</span> <span class="p">)</span> <span class="p">)</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span> <span class="n">idxs</span> <span class="p">)</span></div>
    
<div class="viewcode-block" id="TensorWrapper.shape_to_view"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.shape_to_view">[docs]</a>    <span class="k">def</span> <span class="nf">shape_to_view</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idxs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; This maps the index from the current shape of the view to the view shape.</span>
<span class="sd">        </span>
<span class="sd">        :param list idxs_in: list of indices to be transformed</span>

<span class="sd">        .. note:: no slicing is admitted here. Preprocess ``idxs`` with :py:meth:`expand_idxs` if slicing is required.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ghost_to_view</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape_to_ghost</span><span class="p">(</span> <span class="n">idxs</span> <span class="p">)</span> <span class="p">)</span></div>

<div class="viewcode-block" id="TensorWrapper.view_to_global"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.view_to_global">[docs]</a>    <span class="k">def</span> <span class="nf">view_to_global</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idxs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; This maps the index in view to the global indices of the full tensor wrapper.</span>
<span class="sd">        </span>
<span class="sd">        :param list idxs_in: list of indices to be transformed</span>

<span class="sd">        .. note:: no slicing is admitted here. Preprocess ``idxs`` with :py:meth:`expand_idxs` if slicing is required.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;idx_map&#39;</span><span class="p">][</span><span class="n">d</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span><span class="p">,</span><span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">idxs</span><span class="p">)</span> <span class="p">]</span> <span class="p">)</span></div>

<div class="viewcode-block" id="TensorWrapper.ghost_to_global"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.ghost_to_global">[docs]</a>    <span class="k">def</span> <span class="nf">ghost_to_global</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idxs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; This maps the index from the current ghost shape of the view to the global shape.</span>
<span class="sd">        </span>
<span class="sd">        :param list idxs_in: list of indices to be transformed</span>

<span class="sd">        .. note:: no slicing is admitted here. Preprocess ``idxs`` with :py:meth:`expand_idxs` if slicing is required.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">view_to_global</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">ghost_to_view</span><span class="p">(</span> <span class="n">idxs</span> <span class="p">)</span> <span class="p">)</span></div>
    
<div class="viewcode-block" id="TensorWrapper.shape_to_global"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.shape_to_global">[docs]</a>    <span class="k">def</span> <span class="nf">shape_to_global</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idxs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; This maps the index from the current shape of the view to the global shape.</span>
<span class="sd">        </span>
<span class="sd">        :param list idxs_in: list of indices to be transformed</span>

<span class="sd">        .. note:: no slicing is admitted here. Preprocess ``idxs`` with :py:meth:`expand_idxs` if slicing is required.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">view_to_global</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">ghost_to_view</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape_to_ghost</span><span class="p">(</span> <span class="n">idxs</span> <span class="p">)</span> <span class="p">)</span> <span class="p">)</span></div>

    <span class="c1">######################</span>
    <span class="c1"># CHECKS ON EXTENDED #</span>
    <span class="c1">######################</span>
<div class="viewcode-block" id="TensorWrapper.extended_is_view"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.extended_is_view">[docs]</a>    <span class="k">def</span> <span class="nf">extended_is_view</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idxs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; </span>
<span class="sd">        :return: True if the idxs is in the view shape. False if it is outside</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">(</span> <span class="p">[</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">N</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">N</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">idxs</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">get_view_shape</span><span class="p">())</span> <span class="p">]</span> <span class="p">)</span></div>
    
    <span class="k">def</span> <span class="nf">full_is_view</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">idxs</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">extended_is_view</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">ghost_to_extended</span><span class="p">(</span> <span class="n">idxs</span> <span class="p">)</span> <span class="p">)</span>

    <span class="c1">###############################################</span>
    <span class="c1">#            DATA AND FUNCTIONS               #</span>
    <span class="c1">###############################################</span>
    <span class="k">def</span> <span class="nf">get_fill_level</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">twtype</span> <span class="o">==</span> <span class="s1">&#39;view&#39;</span><span class="p">:</span> <span class="k">return</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span> <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">get_fill_idxs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>
    
    <span class="k">def</span> <span class="nf">get_X</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span>

    <span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    
    <span class="k">def</span> <span class="nf">set_f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">f</span><span class="p">,</span> <span class="n">marshal_f</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="n">f</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">!=</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">marshal_f</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">f_code</span> <span class="o">=</span> <span class="n">marshal</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="vm">__code__</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">reset_f_marshal</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_code</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">code</span> <span class="o">=</span> <span class="n">marshal</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">f_code</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="n">types</span><span class="o">.</span><span class="n">FunctionType</span><span class="p">(</span><span class="n">code</span><span class="p">,</span> <span class="nb">globals</span><span class="p">(),</span> <span class="s2">&quot;f&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;TensorToolbox.TensorWrapper: The tensor wrapper has not function &quot;</span> <span class="o">+</span> \
                <span class="s2">&quot;code to un-marshal. The function is undefined. Define it using &quot;</span> <span class="o">+</span> \
                <span class="s2">&quot;TensorToolbox.TensorWrapper.set_f&quot;</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
    
    <span class="k">def</span> <span class="nf">set_maxprocs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">maxprocs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__maxprocs</span> <span class="o">=</span> <span class="n">maxprocs</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">mpi_map</span>
            <span class="n">MPI_SUPPORT</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="n">MPI_SUPPORT</span> <span class="o">=</span> <span class="kc">False</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__maxprocs</span> <span class="o">!=</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">MPI_SUPPORT</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;TensorToolbox.TensorWrapper: MPI is not supported on this &quot;</span> <span class="o">+</span> \
                          <span class="s2">&quot;machine. The program will run without it.&quot;</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">set_store_object</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">store_object</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">store_object</span> <span class="o">=</span> <span class="n">store_object</span>

<div class="viewcode-block" id="TensorWrapper.__getitem__"><a class="viewcode-back" href="../../../api-tw.html#TensorToolbox.core.TensorWrapper.__getitem__">[docs]</a>    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">idxs_in</span><span class="p">):</span>
        
        <span class="p">(</span><span class="n">lidxs</span><span class="p">,</span><span class="n">out_shape</span><span class="p">,</span><span class="n">transpose_list_shape</span><span class="p">)</span> <span class="o">=</span> <span class="n">expand_idxs</span><span class="p">(</span>
            <span class="n">idxs_in</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ghost_shape</span><span class="p">(),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;fix_dims&#39;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">maps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">][</span><span class="s1">&#39;fix_idxs&#39;</span><span class="p">])</span>
        
        <span class="c1"># Allocate output array</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">out_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">active_weights</span><span class="p">:</span>
                <span class="n">out_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">out_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            
            <span class="c1"># MPI code</span>
            <span class="n">eval_is</span> <span class="o">=</span><span class="p">[]</span>
            <span class="n">eval_idxs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">eval_xx</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="c1"># End MPI code</span>

            <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">idxs</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lidxs</span><span class="p">):</span>

                <span class="c1"># Map ghost indices to global indices</span>
                <span class="n">idxs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ghost_to_global</span><span class="p">(</span> <span class="n">idxs</span> <span class="p">)</span>
                
                <span class="c1"># Compute the weight corresponding to idxs</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">active_weights</span><span class="p">:</span>
                    <span class="n">out_weights</span><span class="p">[</span><span class="n">idxfold</span><span class="p">(</span><span class="n">out_shape</span><span class="p">,</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">jj</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span><span class="p">,</span><span class="n">jj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">idxs</span><span class="p">)])</span>
                
                <span class="c1"># Separate field idxs from parameter idxs                </span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">twtype</span> <span class="o">==</span> <span class="s1">&#39;array&#39;</span><span class="p">:</span>
                    <span class="c1"># Check whether the value has already been computed</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">out</span><span class="p">[</span><span class="n">idxfold</span><span class="p">(</span><span class="n">out_shape</span><span class="p">,</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span>
                    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">idxs</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">eval_idxs</span><span class="p">:</span>
                            <span class="c1"># Evaluate function</span>
                            <span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">ii</span><span class="p">,</span><span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">idxs</span><span class="p">)]</span> <span class="p">)</span>
                            <span class="c1"># MPI code</span>
                            <span class="n">eval_is</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">i</span><span class="p">])</span>
                            <span class="n">eval_idxs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idxs</span><span class="p">)</span>
                            <span class="n">eval_xx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span>
                            <span class="c1"># End MPI code</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">pos</span> <span class="o">=</span> <span class="n">eval_idxs</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">idxs</span><span class="p">)</span>
                            <span class="n">eval_is</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Evaluate function</span>
                    <span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">ii</span><span class="p">,</span><span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">idxs</span><span class="p">)])</span>
                    <span class="n">out</span><span class="p">[</span><span class="n">idxfold</span><span class="p">(</span><span class="n">out_shape</span><span class="p">,</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>

                <span class="c1"># # Check that the idxs belong to the real tensor</span>
                <span class="c1"># isout_flag = not self.full_is_view( idxs )</span>
                <span class="c1">#</span>
                <span class="c1"># if isout_flag:</span>
                <span class="c1">#     out[idxfold(out_shape,i)] = TensorWrapper.FILL_VALUE</span>
                <span class="c1"># else:</span>
                <span class="c1">#     # Map ghost indices to global indices</span>
                <span class="c1">#     idxs = self.full_to_global( idxs )</span>
				<span class="c1"># </span>
                <span class="c1">#     # Separate field idxs from parameter idxs                </span>
                <span class="c1">#     if self.twtype == &#39;array&#39;:</span>
                <span class="c1">#         # Check whether the value has already been computed</span>
                <span class="c1">#         try:</span>
                <span class="c1">#             out[idxfold(out_shape,i)] = self.data[idxs]</span>
                <span class="c1">#         except KeyError:</span>
                <span class="c1">#             if idxs not in eval_idxs:</span>
                <span class="c1">#                 # Evaluate function</span>
                <span class="c1">#                 xx = np.array( [self.X[ii][idx] for ii,idx in enumerate(idxs)] )</span>
                <span class="c1">#                 # MPI code</span>
                <span class="c1">#                 eval_is.append([i])</span>
                <span class="c1">#                 eval_idxs.append(idxs)</span>
                <span class="c1">#                 eval_xx.append(xx)</span>
                <span class="c1">#                 # End MPI code</span>
                <span class="c1">#             else:</span>
                <span class="c1">#                 pos = eval_idxs.index(idxs)</span>
                <span class="c1">#                 eval_is[pos].append(i)</span>
				<span class="c1"># </span>
                <span class="c1">#     else:</span>
                <span class="c1">#         # Evaluate function</span>
                <span class="c1">#         xx = np.array([self.X[ii][idx] for ii,idx in enumerate(idxs)])</span>
                <span class="c1">#         out[idxfold(out_shape,i)] = self.f(xx,self.params)</span>
            
            <span class="c1"># Evaluate missing values</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">eval_xx</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot; [START] Num. of func. eval.: </span><span class="si">%d</span><span class="s2"> &quot;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">eval_xx</span><span class="p">))</span>
                <span class="n">start_eval</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__maxprocs</span> <span class="o">==</span> <span class="kc">None</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">MPI_SUPPORT</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ftype</span> <span class="o">==</span> <span class="s1">&#39;serial&#39;</span><span class="p">:</span>
                        <span class="c1"># Serial evaluation</span>
                        <span class="k">for</span> <span class="p">(</span><span class="n">ii</span><span class="p">,</span><span class="n">idxs</span><span class="p">,</span><span class="n">xx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">eval_is</span><span class="p">,</span> <span class="n">eval_idxs</span><span class="p">,</span> <span class="n">eval_xx</span><span class="p">):</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">store</span><span class="p">()</span>
                            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ii</span><span class="p">:</span>
                                <span class="n">out</span><span class="p">[</span><span class="n">idxfold</span><span class="p">(</span><span class="n">out_shape</span><span class="p">,</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span>
                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">ftype</span> <span class="o">==</span> <span class="s1">&#39;vector&#39;</span><span class="p">:</span>
                        <span class="c1"># Vectorized evaluation</span>
                        <span class="n">eval_xx_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">eval_xx</span><span class="p">)</span>
                        <span class="n">data_mat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">(</span><span class="n">eval_xx_mat</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">ii</span><span class="p">,</span><span class="n">idxs</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">eval_is</span><span class="p">,</span> <span class="n">eval_idxs</span><span class="p">)):</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_mat</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ii</span><span class="p">:</span>
                                <span class="n">out</span><span class="p">[</span><span class="n">idxfold</span><span class="p">(</span><span class="n">out_shape</span><span class="p">,</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">store</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># MPI code</span>
                    <span class="n">eval_res</span> <span class="o">=</span> <span class="n">mpi_map</span><span class="o">.</span><span class="n">mpi_map_code</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_code</span><span class="p">,</span> <span class="n">eval_xx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__maxprocs</span> <span class="p">)</span>
                    <span class="k">for</span> <span class="p">(</span><span class="n">ii</span><span class="p">,</span><span class="n">idxs</span><span class="p">,</span><span class="n">res</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">eval_is</span><span class="p">,</span> <span class="n">eval_idxs</span><span class="p">,</span> <span class="n">eval_res</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span> <span class="o">=</span> <span class="n">res</span>
                        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ii</span><span class="p">:</span>
                            <span class="n">out</span><span class="p">[</span><span class="n">idxfold</span><span class="p">(</span><span class="n">out_shape</span><span class="p">,</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">store</span><span class="p">()</span>
                    <span class="c1"># End MPI code</span>
                <span class="n">stop_eval</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot; [DONE] Num. of func. eval.: </span><span class="si">%d</span><span class="s2"> - Avg. time of func. eval.: </span><span class="si">%f</span><span class="s2">s - Tot. time: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">eval_xx</span><span class="p">),(</span><span class="n">stop_eval</span><span class="o">-</span><span class="n">start_eval</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">eval_xx</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__maxprocs</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">eval_xx</span><span class="p">))</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__maxprocs</span> <span class="o">!=</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">1</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="p">(</span><span class="n">stop_eval</span><span class="o">-</span><span class="n">start_eval</span><span class="p">)))</span> <span class="p">))</span>
            
            <span class="c1"># Apply weights if needed</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">active_weights</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">*=</span> <span class="n">out_weights</span>
            
            <span class="k">if</span> <span class="n">transpose_list_shape</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span> <span class="n">out</span> <span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">out_shape</span><span class="p">)))</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">)</span> <span class="p">)</span>
            
        <span class="k">else</span><span class="p">:</span>
            <span class="n">idxs</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">lidxs</span><span class="p">))</span>
            <span class="c1"># Map ghost indices to global indices</span>
            <span class="n">idxs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ghost_to_global</span><span class="p">(</span> <span class="n">idxs</span> <span class="p">)</span>
            <span class="c1"># Compute weight if necessary</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">active_weights</span><span class="p">:</span>
                <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">jj</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span><span class="p">,</span><span class="n">jj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">idxs</span><span class="p">)])</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">twtype</span> <span class="o">==</span> <span class="s1">&#39;array&#39;</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span>
                <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                    <span class="c1"># Evaluate function</span>
                    <span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">ii</span><span class="p">,</span><span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">idxs</span><span class="p">)])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">store</span><span class="p">()</span>
                    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">ii</span><span class="p">,</span><span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">idxs</span><span class="p">)]),</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
            <span class="c1"># Apply the weight if necessary</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">active_weights</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">*=</span> <span class="n">w</span>
        
        <span class="k">return</span> <span class="n">out</span></div></div>
</pre></div>

          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">TensorToolbox 0.3.3 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2013-2015, Daniele Bigoni.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.6.
    </div>
  </body>
</html>